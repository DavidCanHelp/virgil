// Copyright 2012 Google Inc. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

// Handles assembly-level details of allocating memory on x86.
class X86Allocator {
	def mach: MachProgram;
	def stub: bool;
	def alwaysGc: bool;
	var objLoc: int;
	var sizeLoc: int;
	var allocStubAddr: Addr;
	var frame: MachFrame;
	var gcmeth: IrMethod;

	new(mach, stub, alwaysGc) { }
	def init(getFrame: SsaRegion -> MachFrame) {
		if (stub) {
			// initialize locations based on calling convention to RiRuntime.gc()
			allocStubAddr = Address.new(mach.layout.codeRegion, "alloc_stub");
			var ri_gc = mach.runtime.ri_gc;
			if (ri_gc != null) {
				// call the RiRuntime.gc() method
				gcmeth = ri_gc.spec.asMethod();
				frame = getFrame(gcmeth.ssa);
				objLoc = frame.conv.calleeRet(0);
				sizeLoc = frame.conv.calleeParam(1); // param 0 = "this"
			} else {
				// there is no appropriate RiRuntime.gc() method
				objLoc = X86MachRegs.EAX;
				sizeLoc = X86MachRegs.EAX;
			}
		}
	}
	def gen_alloc(g: MachCodeGen, i: SsaApplyOp, mv: MachVar) {
		var gen = X86CodeGen.!(g);
		var size = i.inputs(0).dest;
		if (stub) {
			// generate a call to the allocation stub
			gen.dfnAt(mv, objLoc);
			var lp = if(mach.runtime.gc != null, gen.livePoint());
			gen.kill(X86MachRegs.ALL);
			gen.useAt(gen.makeVar(size), sizeLoc);
			gen.gen("alloc", asm_alloc_rt, (gen, lp, i.source));
		} else {
			// generate inlined (test) allocation
			gen.hint(size, mv);
			gen.gen("alloc", asm_alloc_test, (gen, gen.dfngpr(mv), gen.gpr(size), i.source));
		}
	}
	def asm_alloc_test(gen: X86CodeGen, dest: int, sz: int, source: Source) {
		// exchange-add [CiRuntime.heapCurLoc] with size
		var rd = gen.r(dest), ra = gen.r(sz);
		if (rd != ra) gen.asm.movd_rm_r(rd, ra);
		var pos = gen.asm.pos();
		gen.asm.xadd(X86Addrs.ABS_PATCH, rd);
		gen.recordPatch(pos, mach.runtime.rt_heap_cur_loc);
	}
	def asm_alloc_rt(gen: X86CodeGen, lp: int, source: Source) {
		// call a shared allocation stub routine
		gen.asm.call_addr(allocStubAddr);
		var off = gen.codeOffset();
		if (gen.rtgc != null) gen.rtgc.recordStackRefMap(off, gen.buildStackMap(null, lp));
		if (gen.rtsrc != null) gen.rtsrc.recordReturnSource(off, source);
	}
	def genAllocStub(u: MachDataEncoder) {
		if (!stub) return;
		// generate the shared allocation routine
		allocStubAddr.absolute = u.endAddr();
		var asm = X86MachAssembler.new(mach, u);
		var sizeReg = asm.loc_r(sizeLoc);

		if (alwaysGc) {
			// testing mode: just call the GC directly for every allocation
			if (gcmeth == null) return mach.compiler.ERROR.fail("no collector method found");
			return jumpRiGc(asm);
		}

		// %sizeReg = alloc(%sizeReg = size)
		asm.movd_r_rm(X86MachRegs.SCRATCH, sizeReg);
		// add size = size + [heapCurLoc]
		var addPos = asm.pos();
		asm.add.r_rm(sizeReg, X86Addrs.ABS_PATCH);
		asm.recordPatch(addPos, mach.runtime.rt_heap_cur_loc);
		// check for addition overflow
		asm.jmpx(X86Conds.C, 0);
		var branchPos1 = asm.pos() - 1;
		// compare with [heapEndLoc]
		var cmpPos = asm.pos();
		asm.cmp.r_rm(sizeReg, X86Addrs.ABS_PATCH);
		asm.recordPatch(cmpPos, mach.runtime.rt_heap_end_loc);

		if (gcmeth == null) {
			// branch to the fatal address
			asm.jmpx_addr(X86Conds.A, mach.runtime.getFatalAddress(V3Exception.HeapOverflow));
		} else {
			// branch forward to the slow path
			asm.jmpx(X86Conds.A, 0);
		}

		var branchPos2 = asm.pos() - 1;
		asm.movd_rm_r(X86Addrs.ABS_PATCH, sizeReg);
		asm.recordPatch(branchPos2 + 1, mach.runtime.rt_heap_cur_loc);
		asm.sub.r_rm(sizeReg, X86MachRegs.SCRATCH);
		asm.ret();

		if (gcmeth == null) return;
		// slow path: call RiRuntime.gc
		var callRtPos = asm.pos();
		asm.encoder.at(branchPos1).i1(callRtPos - (branchPos1 + 1));
		asm.encoder.at(branchPos2).i1(callRtPos - (branchPos2 + 1));
		asm.encoder.atEnd();
		// callerParam(0) = this
		// callerParam(1) = size
		asm.movd_rm_r(sizeReg, X86MachRegs.SCRATCH); // reload saved size
		jumpRiGc(asm); // load other args and simply jump into runtime
	}
	def jumpRiGc(asm: X86MachAssembler) {
		// callerParam(2) = ip
		var ipRm = asm.loc_rm(frame, frame.conv.calleeParam(2));
		asm.movd_rm_rm(ipRm, X86Regs.ESP.indirect(), X86MachRegs.SCRATCH);
		// callerParam(3) = sp
		var spReg = asm.loc_r(frame.conv.calleeParam(3));
		asm.lea(spReg, X86Addr.new(X86Regs.ESP, 1, mach.data.addressSize));
		asm.jmpx_addr(null, mach.layout.addrOfMethod(gcmeth));
		// no need to return, this is a tail call
	}
}
