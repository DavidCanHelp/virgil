// Copyright 2017 Google Inc. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

def TRUNCATE = true;
def NO_TRUNCATE = false;
class WasmCodeGen extends ArchCodeGen {
	def wasm: WasmProgram;
	def buffer: MachDataBuffer;
	def rt: MachRuntime;
	def m = SsaInstrMatcher.new();

	def MATCH_NEG = true;
	def MATCH_OP_I = true;

	new(context: SsaContext, wasm: WasmProgram, rt) super(context, wasm.mach, ArmMachRegs.regs) {
		anyReg = ArmMachRegs.GPR;
	}
	def visitApply(block: SsaBlock, i: SsaApplyOp) {
		match (i.op.opcode) {
			IntAdd => emitIntBinop(i, WasmOp.I32_ADD, WasmOp.I64_ADD);
			IntSub => emitIntBinop(i, WasmOp.I32_SUB, WasmOp.I64_SUB);
			IntMul => emitIntBinop(i, WasmOp.I32_MUL, WasmOp.I64_MUL);
			IntDiv => emitIntBinopSU(i, WasmOp.I32_DIV_S, WasmOp.I32_DIV_U, WasmOp.I64_DIV_S, WasmOp.I64_DIV_U);
			IntMod => emitIntBinopSU(i, WasmOp.I32_REM_S, WasmOp.I32_REM_U, WasmOp.I64_REM_S, WasmOp.I64_REM_U);
			IntAnd => emitIntBinop(i, WasmOp.I32_AND, WasmOp.I64_AND);
			IntOr  => emitIntBinop(i, WasmOp.I32_OR, WasmOp.I64_OR);
			IntXor => emitIntBinop(i, WasmOp.I32_XOR, WasmOp.I64_XOR);
			IntShl => emitIntBinop(i, WasmOp.I32_SHL, WasmOp.I64_SHL);
			IntSar => emitIntBinop(i, WasmOp.I32_SHR_S, WasmOp.I64_SHR_S);
			IntShr => emitIntBinop(i, WasmOp.I32_SHR_U, WasmOp.I64_SHR_U);
			IntConvert => emitIntConvert(i);
			BoolNot => {
				// XXX: match and invert comparisons
				emit3(WasmOp.I32_XOR.opcode, dfn(i), use(i.input0()), useInt(1));
			}
			BoolEq => emitBinop(i, WasmOp.I32_EQ);
			RefEq  => emitBinop(i, WasmOp.I32_EQ);
			IntEq   => emitIntBinop(i, WasmOp.I32_EQ, WasmOp.I64_EQ);
			IntLt   => emitIntBinopSU(i, WasmOp.I32_LT_S, WasmOp.I32_LT_U, WasmOp.I64_LT_S, WasmOp.I64_LT_U);
			IntLteq => emitIntBinopSU(i, WasmOp.I32_LE_S, WasmOp.I32_LE_U, WasmOp.I64_LE_S, WasmOp.I64_LE_U);
			UnsignedLt => emitBinop(i, WasmOp.I32_LT_U);
			UnsignedLteq => emitBinop(i, WasmOp.I32_LE_U);
			UnsignedGt => emitBinop(i, WasmOp.I32_GT_U);
			UnsignedGteq => emitBinop(i, WasmOp.I32_GE_U);
			PtrLoad => {
				var ty = i.op.typeArgs[1];
				var wop: WasmOp, size = mach.sizeOf(ty);
				match (size) {
					1 => wop = if(mach.isSigned(ty), WasmOp.I32_LOAD8_S, WasmOp.I32_LOAD8_U);
					2 => wop = if(mach.isSigned(ty), WasmOp.I32_LOAD16_S, WasmOp.I32_LOAD16_U);
					4 => wop = WasmOp.I32_LOAD;
					8 => wop = WasmOp.I64_LOAD;
					_ => context.fail("invalid load size");
				}
				var t = matchAddress(i.input0()), opcode = wop.opcode | ArchInstrs.FLAG_LOAD;
				if (t.1 == null) {
					emit3(opcode, dfn(i), useImm(t.0), useInt(0));
				} else {
					emit3(opcode, dfn(i), useImm(t.0), use(t.1));
				}
			}
			PtrStore => {
				var wop: WasmOp, size = mach.sizeOf(i.op.typeArgs[1]);
				match (size) {
					1 => wop = WasmOp.I32_STORE8;
					2 => wop = WasmOp.I32_STORE16;
					4 => wop = WasmOp.I32_STORE;
					8 => wop = WasmOp.I64_STORE;
					_ => context.fail("invalid store size");
				}
				var t = matchAddress(i.input0()), opcode = wop.opcode | ArchInstrs.FLAG_STORE;
				if (t.1 == null) {
					emit3(opcode, useImm(t.0), useInt(0), use(i.input1()));
				} else {
					emit3(opcode, useImm(t.0), use(t.1), use(i.input1()));
				}
			}
			PtrAdd => emitBinop(i, WasmOp.I32_ADD);
			PtrSub => emitBinop(i, WasmOp.I32_SUB);
			ConditionalThrow => {
				emit1(WasmOp.IF.opcode, use(i.inputs[0].dest));
				emitN(WasmOp.UNREACHABLE.opcode);
				emitN(WasmOp.END.opcode);
			}
			CallAddress => {
				dfnAll(i);
				for (j = 1; j < i.inputs.length; j++) {
					use(i.inputs[j].dest);  // use arguments
				}
				var target = i.inputs[0].dest;
				if (SsaConst.?(target)) {
					var val = SsaConst.!(target).val, m: IrMethod;
					if (FuncVal.?(val)) m = FuncVal.!(val).memberRef.asMethod();
					else if (Address<IrMethod>.?(val)) m = Address<IrMethod>.!(val).val;
					else context.fail("constant target is not an address or function value");
					useInt(m.machIndex);
					emitN(WasmOp.CALL.opcode);
				} else {
					var paramTypes = Arrays.range(i.op.paramTypes, 1, i.op.paramTypes.length);
					var sigIndex = wasm.getSigIndexByType(paramTypes, i.op.resultType);
					useInt(int.!(sigIndex));
					use(i.inputs[0].dest); // use destination
					emitN(WasmOp.CALL_INDIRECT.opcode);
				}
				// XXX: match Call(PtrLoad(PtrAdd(#meta, x))
			}
			Alloc => ;      // TODO
			MachSystemOp => ; // TODO
			_ => return context.fail("unexpected opcode in WASM codegen");
		}
	}
	def visitThrow(block: SsaBlock, i: SsaThrow) {
		emitN(WasmOp.UNREACHABLE.opcode); // TODO: record exception location
	}
	def visitIf(block: SsaBlock, i: SsaIf) {
		var depth = 0;
		emit2(WasmOp.BR_IF.opcode, use(i.inputs[0].dest), useInt(depth));  // TODO
	}
	def visitSwitch(block: SsaBlock, i: SsaSwitch) {} // TODO
	def visitGoto(block: SsaBlock, target: SsaGoto) {} // TODO
	def visitReturn(block: SsaBlock, i: SsaReturn) {
		for (j < i.inputs.length) use(i.inputs[j].dest);
		emitN(ArchInstrs.ARCH_RET);
	}
	def emitIntConvert(i: SsaApplyOp) {
		var ft = IntType.!(i.op.paramTypes[0]), tt = IntType.!(i.op.resultType);
		if (ft.width > 32 && tt.width <= 32) {
			ft = Int.TYPE;
			emit2(WasmOp.I32_WRAP_I64.opcode, dfn(i), use(i.input0()));
		} else if (ft.width <= 32 && tt.width > 32) {
			var op = if(tt.signed, WasmOp.I64_EXTEND_S_I32, WasmOp.I64_EXTEND_U_I32);
			emit2(op.opcode, dfn(i), use(i.input0()));
		}
		if (tt.width != 32) {
			if (tt.signed) emitSignExtend(i, tt);
			else emitZeroExtend(i, tt);
		}
	}
	def emitSignExtend(i: SsaInstr, tt: IntType) {
		if (tt.width < 32) {
			emit3(WasmOp.I32_SHL.opcode, dfn(i), use(i), useInt(32 - tt.width));
			emit3(WasmOp.I32_SHR_S.opcode, dfn(i), use(i), useInt(32 - tt.width));
		} else if (tt.width > 32 && tt.width < 64) {
			emit3(WasmOp.I64_SHL.opcode, dfn(i), use(i), useInt(32 - tt.width));
			emit3(WasmOp.I64_SHR_S.opcode, dfn(i), use(i), useInt(32 - tt.width));
		}
	}
	def emitZeroExtend(i: SsaInstr, tt: IntType) {
		if (tt.width < 32) {
			emit3(WasmOp.I32_AND.opcode, dfn(i), use(i), useImm(tt.max));
		} else if (tt.width > 32 && tt.width < 64) {
			emit3(WasmOp.I64_AND.opcode, dfn(i), use(i), useImm(tt.max));
		}
	}
	def matchAddress(a: SsaInstr) -> (Val, SsaInstr) {
		if (SsaConst.?(a)) return (SsaConst.!(a).val, null);
		var add = cover(Opcode.PtrAdd, a);
		if (add != null) {
			var r = add.input1();
			if (SsaConst.?(r)) return (SsaConst.!(r).val, add.input0());
		}
		return (null, a);
	}
	def emitIntBinop(i: SsaApplyOp, op32: WasmOp, op64: WasmOp) {
		var op = if(IntType.!(i.op.typeArgs[0]).width <= 32, op32, op64);
		emit3(op.opcode, dfn(i), use(i.input0()), use(i.input1()));
	}
	def emitIntBinopSU(i: SsaApplyOp, op32s: WasmOp, op32u: WasmOp, op64s: WasmOp, op64u: WasmOp) {
		if (isSigned(i.op)) emitIntBinop(i, op32s, op64s);
		else emitIntBinop(i, op32u, op64u);
	}
	def emitBinop(i: SsaApplyOp, op: WasmOp) {
		emit3(op.opcode, dfn(i), use(i.input0()), use(i.input1()));
	}
	// Assembling support
	def assemble(opcode: int, a: Array<Operand>) {
		match (opcode) {
			ArchInstrs.ARCH_RET => return buffer.i1(WasmOp.RETURN.opcode);
		}
		if (opcode > 0 && WasmOpNames.array[opcode] != null) buffer.i1(opcode);
		else context.fail1("cannot assemble WASM opcode %1", opcode);
		// emit immediates for specific opcodes
		match (opcode) {
			ArchInstrs.ARCH_RET => return buffer.i1(WasmOp.RETURN.opcode);
			WasmOp.BLOCK.opcode,
			WasmOp.IF.opcode => buffer.i1(WASM_VOID_TYPE);

			WasmOp.I32_LOAD8_S.opcode,
			WasmOp.I32_LOAD8_U.opcode,
			WasmOp.I64_LOAD8_S.opcode,
			WasmOp.I64_LOAD8_U.opcode,
			WasmOp.I32_STORE8.opcode,
			WasmOp.I64_STORE8.opcode => asmls(1, a);

			WasmOp.I32_LOAD16_S.opcode,
			WasmOp.I32_LOAD16_U.opcode,
			WasmOp.I64_LOAD16_S.opcode,
			WasmOp.I64_LOAD16_U.opcode,
			WasmOp.I32_STORE16.opcode,
			WasmOp.I64_STORE16.opcode => asmls(2, a);

			WasmOp.I32_LOAD.opcode,
			WasmOp.F32_LOAD.opcode,
			WasmOp.I64_LOAD32_S.opcode,
			WasmOp.I64_LOAD32_U.opcode,
			WasmOp.I32_STORE.opcode,
			WasmOp.F32_STORE.opcode,
			WasmOp.I64_STORE32.opcode => asmls(3, a);

			WasmOp.I64_LOAD.opcode,
			WasmOp.F64_LOAD.opcode,
			WasmOp.I64_STORE.opcode,
			WasmOp.F64_STORE.opcode => asmls(4, a);

			WasmOp.CALL.opcode => {
				buffer.i4leb(asInt(a[a.length - 1])); // function_index
			}
			WasmOp.CALL_INDIRECT.opcode => {
				buffer.i4leb(asInt(a[a.length - 1])); // type_index
				buffer.i1(0);                         // reserved
			}
		}
	}
	def asInt(o: Operand) -> int {
		return Int.unbox(Operand.Immediate.!(o).val);
	}
	def asmls(logAlign: int, a: Array<Operand>) {
		buffer.i1(logAlign);       // flags = alignment
		buffer.i4leb(asInt(a[0])); // offset
	}
	// Printing support
	def renderSpecific(buf: ArchInstrRenderer, opcode: int, a: Array<Operand>) -> bool {
		var n = WasmOpNames.array[opcode];
		if (n == null) return false;
		buf.putArch(n, a);
		return true;
	}
}
// A stack instruction generator specifically for WASM.
class WasmStackInstrGen extends StackInstrGen {
	def insertLoadLocal(v: MachVar, next: ArchInstr) {
		insertBefore(ArchInstr.new(WasmOp.GET_LOCAL.opcode, [Operand.Use(v.ssa, v, 0)]), next);
	}
	def insertStoreLocal(v: MachVar, pop: bool, next: ArchInstr) {
		var opcode = if(pop, WasmOp.SET_LOCAL.opcode, WasmOp.TEE_LOCAL.opcode);
		insertBefore(ArchInstr.new(opcode, [Operand.Def(v.ssa, v, 0)]), next);
	}
	def insertPop(v: MachVar, next: ArchInstr) {
		insertBefore(ArchInstr.new(WasmOp.DROP.opcode, []), next);
	}
	def insertLoadConst(t: Type, val: Val, next: ArchInstr) {
		match (t.typeCon.kind) {
			V3Kind.INT => {
				var opcode = if(IntType.!(t).width > 32, WasmOp.I64_CONST.opcode, WasmOp.I32_CONST.opcode);
				insertBefore(ArchInstr.new(opcode, [Operand.Immediate(val)]), next);
			}
			// TODO: reference constants
			_ => return V3.fail("unimplemented");
		}
	}
}
def WASM_VOID_TYPE = 0;

// Constants for wasm opcodes.
enum WasmOp(opcode: byte, text_name: string) {
	UNREACHABLE(0x00, "unreachable"),
	NOP(0x01, "nop"),
	BLOCK(0x02, "block"),
	LOOP(0x03, "loop"),
	IF(0x04, "if"),
	ELSE(0x05, "else"),
	END(0x0b, "end"),
	BR(0x0c, "br"),
	BR_IF(0x0d, "br_if"),
	BR_TABLE(0x0e, "br_table"),
	RETURN(0x0f, "return"),
	CALL(0x10, "call"),
	CALL_INDIRECT(0x11, "call_indirect"),
	DROP(0x1a, "drop"),
	SELECT(0x1b, "select"),
	GET_LOCAL(0x20, "get_local"),
	SET_LOCAL(0x21, "set_local"),
	TEE_LOCAL(0x22, "tee_local"),
	GET_GLOBAL(0x23, "get_global"),
	SET_GLOBAL(0x24, "set_global"),
	I32_LOAD(0x28, "i32.load"),
	I64_LOAD(0x29, "i64.load"),
	F32_LOAD(0x2a, "f32.load"),
	F64_LOAD(0x2b, "f64.load"),
	I32_LOAD8_S(0x2c, "i32.load8_s"),
	I32_LOAD8_U(0x2d, "i32.load8_u"),
	I32_LOAD16_S(0x2e, "i32.load16_s"),
	I32_LOAD16_U(0x2f, "i32.load16_u"),
	I64_LOAD8_S(0x30, "i64.load8_s"),
	I64_LOAD8_U(0x31, "i64.load8_u"),
	I64_LOAD16_S(0x32, "i64.load16_s"),
	I64_LOAD16_U(0x33, "i64.load16_u"),
	I64_LOAD32_S(0x34, "i64.load32_s"),
	I64_LOAD32_U(0x35, "i64.load32_u"),
	I32_STORE(0x36, "i32.store"),
	I64_STORE(0x37, "i64.store"),
	F32_STORE(0x38, "f32.store"),
	F64_STORE(0x39, "f64.store"),
	I32_STORE8(0x3a, "i32.store8"),
	I32_STORE16(0x3b, "i32.store16"),
	I64_STORE8(0x3c, "i64.store8"),
	I64_STORE16(0x3d, "i64.store16"),
	I64_STORE32(0x3e, "i64.store32"),
	CURRENT_MEMORY(0x3f, "current_memory"),
	GROW_MEMORY(0x40, "grow_memory"),
	I32_CONST(0x41, "i32.const"),
	I64_CONST(0x42, "i64.const"),
	F32_CONST(0x43, "f32.const"),
	F64_CONST(0x44, "f64.const"),
	I32_EQZ(0x45, "i32.eqz"),
	I32_EQ(0x46, "i32.eq"),
	I32_NE(0x47, "i32.ne"),
	I32_LT_S(0x48, "i32.lt_s"),
	I32_LT_U(0x49, "i32.lt_u"),
	I32_GT_S(0x4a, "i32.gt_s"),
	I32_GT_U(0x4b, "i32.gt_u"),
	I32_LE_S(0x4c, "i32.le_s"),
	I32_LE_U(0x4d, "i32.le_u"),
	I32_GE_S(0x4e, "i32.ge_s"),
	I32_GE_U(0x4f, "i32.ge_u"),
	I64_EQZ(0x50, "i64.eqz"),
	I64_EQ(0x51, "i64.eq"),
	I64_NE(0x52, "i64.ne"),
	I64_LT_S(0x53, "i64.lt_s"),
	I64_LT_U(0x54, "i64.lt_u"),
	I64_GT_S(0x55, "i64.gt_s"),
	I64_GT_U(0x56, "i64.gt_u"),
	I64_LE_S(0x57, "i64.le_s"),
	I64_LE_U(0x58, "i64.le_u"),
	I64_GE_S(0x59, "i64.ge_s"),
	I64_GE_U(0x5a, "i64.ge_u"),
	F32_EQ(0x5b, "f32.eq"),
	F32_NE(0x5c, "f32.ne"),
	F32_LT(0x5d, "f32.lt"),
	F32_GT(0x5e, "f32.gt"),
	F32_LE(0x5f, "f32.le"),
	F32_GE(0x60, "f32.ge"),
	F64_EQ(0x61, "f64.eq"),
	F64_NE(0x62, "f64.ne"),
	F64_LT(0x63, "f64.lt"),
	F64_GT(0x64, "f64.gt"),
	F64_LE(0x65, "f64.le"),
	F64_GE(0x66, "f64.ge"),
	I32_CLZ(0x67, "i32.clz"),
	I32_CTZ(0x68, "i32.ctz"),
	I32_POPCNT(0x69, "i32.popcnt"),
	I32_ADD(0x6a, "i32.add"),
	I32_SUB(0x6b, "i32.sub"),
	I32_MUL(0x6c, "i32.mul"),
	I32_DIV_S(0x6d, "i32.div_s"),
	I32_DIV_U(0x6e, "i32.div_u"),
	I32_REM_S(0x6f, "i32.rem_s"),
	I32_REM_U(0x70, "i32.rem_u"),
	I32_AND(0x71, "i32.and"),
	I32_OR(0x72, "i32.or"),
	I32_XOR(0x73, "i32.xor"),
	I32_SHL(0x74, "i32.shl"),
	I32_SHR_S(0x75, "i32.shr_s"),
	I32_SHR_U(0x76, "i32.shr_u"),
	I32_ROTL(0x77, "i32.rotl"),
	I32_ROTR(0x78, "i32.rotr"),
	I64_CLZ(0x79, "i64.clz"),
	I64_CTZ(0x7a, "i64.ctz"),
	I64_POPCNT(0x7b, "i64.popcnt"),
	I64_ADD(0x7c, "i64.add"),
	I64_SUB(0x7d, "i64.sub"),
	I64_MUL(0x7e, "i64.mul"),
	I64_DIV_S(0x7f, "i64.div_s"),
	I64_DIV_U(0x80, "i64.div_u"),
	I64_REM_S(0x81, "i64.rem_s"),
	I64_REM_U(0x82, "i64.rem_u"),
	I64_AND(0x83, "i64.and"),
	I64_OR(0x84, "i64.or"),
	I64_XOR(0x85, "i64.xor"),
	I64_SHL(0x86, "i64.shl"),
	I64_SHR_S(0x87, "i64.shr_s"),
	I64_SHR_U(0x88, "i64.shr_u"),
	I64_ROTL(0x89, "i64.rotl"),
	I64_ROTR(0x8a, "i64.rotr"),
	F32_ABS(0x8b, "f32.abs"),
	F32_NEG(0x8c, "f32.neg"),
	F32_CEIL(0x8d, "f32.ceil"),
	F32_FLOOR(0x8e, "f32.floor"),
	F32_TRUNC(0x8f, "f32.trunc"),
	F32_NEAREST(0x90, "f32.nearest"),
	F32_SQRT(0x91, "f32.sqrt"),
	F32_ADD(0x92, "f32.add"),
	F32_SUB(0x93, "f32.sub"),
	F32_MUL(0x94, "f32.mul"),
	F32_DIV(0x95, "f32.div"),
	F32_MIN(0x96, "f32.min"),
	F32_MAX(0x97, "f32.max"),
	F32_COPYSIGN(0x98, "f32.copysign"),
	F64_ABS(0x99, "f64.abs"),
	F64_NEG(0x9a, "f64.neg"),
	F64_CEIL(0x9b, "f64.ceil"),
	F64_FLOOR(0x9c, "f64.floor"),
	F64_TRUNC(0x9d, "f64.trunc"),
	F64_NEAREST(0x9e, "f64.nearest"),
	F64_SQRT(0x9f, "f64.sqrt"),
	F64_ADD(0xa0, "f64.add"),
	F64_SUB(0xa1, "f64.sub"),
	F64_MUL(0xa2, "f64.mul"),
	F64_DIV(0xa3, "f64.div"),
	F64_MIN(0xa4, "f64.min"),
	F64_MAX(0xa5, "f64.max"),
	F64_COPYSIGN(0xa6, "f64.copysign"),
	I32_WRAP_I64(0xa7, "i32.wrap_i64"),
	I32_TRUNC_S_F32(0xa8, "i32.trunc_s_f32"),
	I32_TRUNC_U_F32(0xa9, "i32.trunc_u_f32"),
	I32_TRUNC_S_F64(0xaa, "i32.trunc_s_f64"),
	I32_TRUNC_U_F64(0xab, "i32.trunc_u_f64"),
	I64_EXTEND_S_I32(0xac, "i64.extend_s_i32"),
	I64_EXTEND_U_I32(0xad, "i64.extend_u_i32"),
	I64_TRUNC_S_F32(0xae, "i64.trunc_s_f32"),
	I64_TRUNC_U_F32(0xaf, "i64.trunc_u_f32"),
	I64_TRUNC_S_F64(0xb0, "i64.trunc_s_f64"),
	I64_TRUNC_U_F64(0xb1, "i64.trunc_u_f64"),
	F32_CONVERT_S_I32(0xb2, "f32.convert_s_i32"),
	F32_CONVERT_U_I32(0xb3, "f32.convert_u_i32"),
	F32_CONVERT_S_I64(0xb4, "f32.convert_s_i64"),
	F32_CONVERT_U_I64(0xb5, "f32.convert_u_i64"),
	F32_DEMOTE_F64(0xb6, "f32.demote_f64"),
	F64_CONVERT_S_I32(0xb7, "f64.convert_s_i32"),
	F64_CONVERT_U_I32(0xb8, "f64.convert_u_i32"),
	F64_CONVERT_S_I64(0xb9, "f64.convert_s_i64"),
	F64_CONVERT_U_I64(0xba, "f64.convert_u_i64"),
	F64_PROMOTE_F32(0xbb, "f64.promote_f32"),
	I32_REINTERPRET_F32(0xbc, "i32.reinterpret_f32"),
	I64_REINTERPRET_F64(0xbd, "i64.reinterpret_f64"),
	F32_REINTERPRET_I32(0xbe, "f32.reinterpret_i32"),
	F64_REINTERPRET_I64(0xbf, "f64.reinterpret_i64"),
}

// Contains an index from opcode number to name.
component WasmOpNames {
	def array = Array<string>.new(256);
	new() {
                for (op in WasmOp) array[op.opcode] = op.text_name;
	}
}

type CfgInstr {
	case Block(t: byte, bi: SsaBlockInfo);
	case Loop(bi: SsaBlockInfo);
	case Body(bi: SsaBlockInfo);
	case If(t: byte, join: SsaBlockInfo);
	case Else;
	case End;
	case Br(bi: SsaBlockInfo, depth: int);
	case BrIf(bi: SsaBlockInfo, depth: int);
	case BrTable(min: int, depths: Array<int>);
}

// Restructures an a reducible control flow graph into WASM
// structured control flow by using the dominator tree.
class CfgRestructurer(order: SsaBlockOrder) {
	def blocks = order.order;
	def code = Vector<CfgInstr>.new();
	def stack = Vector<SsaBlockInfo>.new();
	def gen() -> Vector<CfgInstr> {
		order.computeDominators();
		hoistLoopRemaindersInDomTree(blocks[0]);
		visit(blocks[0]);
		optimize();
		return code;
	}
	def visit(bi: SsaBlockInfo) {
		var loopRemainder: List<SsaBlockInfo>;
		if (bi.loop != null) {
			loopRemainder = findLoopRemainder(bi);
			emitJoinBlocks(loopRemainder);
			emit(CfgInstr.Loop(bi));
		}
		// skip blocks bodies that are empty with no phis
		if (bodyNotEmpty(bi)) emit(CfgInstr.Body(bi));
		var end = bi.block.end();
		if (SsaIf.?(end)) {
			var si = SsaIf.!(end);
			var tt = blocks[si.trueBlock().mark], ft = blocks[si.falseBlock().mark];
			if (tt.dom_parent != bi) {
				// true block is part of a loop remainder.
				emit(CfgInstr.BrIf(tt, getRelDepth(tt)));
				visitOrBranchTo(bi, ft);
			} else {
				// emit extra blocks for joins
				var joins = findJoins(bi);
				var join: SsaBlockInfo;
				var blocks: List<SsaBlockInfo>;
				// emit an if-then-else
				if (joins == null) {
					emit(CfgInstr.If(WasmType.Void, null));
					blocks = null;
					join = null;
				} else {
					emitJoinBlocks(blocks = joins.tail);
					emit(CfgInstr.If(WasmType.Void, join = joins.head));
				}
				visitOrBranchTo(bi, tt);
				emit(CfgInstr.Else);
				visitOrBranchTo(bi, ft);
				emit(CfgInstr.End);
				// emit the ends for previous blocks
				if (join != null) visit(join);
				emitJoinEnds(blocks);
			}

		} else if (SsaGoto.?(end)) {
			var target = blocks[end.succs[0].dest.mark];
			if (target.dom_parent == bi) {
				visit(target);  // inline the block if dominated
			} else {
				emit(CfgInstr.Br(target, getRelDepth(target)));
			}
		} else if (SsaSwitch.?(end)) {
			// Emit a series of nested blocks and a br_table
			var list: List<SsaBlockInfo>;
			for (ci = bi.dom_child; ci != null; ci = ci.dom_sibling) {
				list = List.new(ci, list);
			}
			emitJoinBlocks(list);
			var succs = bi.block.succs();
			var depths = Array<int>.new(succs.length);
			for (i < depths.length) {
				depths[i] = getRelDepth(blocks[succs[i].dest.mark]);
			}
			emit(CfgInstr.BrTable(SsaSwitch.!(end).minValue, depths));
			emitJoinEnds(list);
		}
		if (bi.loop != null) {
			emit(CfgInstr.End);
			emitJoinEnds(loopRemainder);
		}
	}
	def bodyNotEmpty(bi: SsaBlockInfo) -> bool {
		var b = bi.block, end = b.end();
		if (b.next != end) return true;
		if (SsaGoto.?(end)) {
			return b.succs()[0].dest.hasPhis();
		}
		return true;
	}
	def visitOrBranchTo(pi: SsaBlockInfo, target: SsaBlockInfo) {
		if (target.dom_parent == pi && target.block.preds.length == 1) {
			visit(target);
		} else {
			emit(CfgInstr.Br(target, getRelDepth(target)));
		}
	}
	def emit(i: CfgInstr) {
		match (i) {
			Loop(bi) => stack.add(bi);
			Block(t, bi) => stack.add(bi);
			If(t, join) => stack.add(join);
			End => stack.length--;
			_ => ;
		}
		code.add(i);
	}
	def emitJoinBlocks(list: List<SsaBlockInfo>) {
		for (j = Lists.reverse(list); j != null; j = j.tail) {
			emit(CfgInstr.Block(WasmType.Void, j.head));
		}
	}
	def emitJoinEnds(list: List<SsaBlockInfo>) {
		for (j = list; j != null; j = j.tail) {
			emit(CfgInstr.End);
			visit(j.head);
		}
	}
	def getRelDepth(bi: SsaBlockInfo) -> int {
		for (depth = 0; depth < stack.length; depth++) {
			if (stack[stack.length - depth - 1] == bi) return depth;
		}
		return V3.fail1("block @%1 not found on stack", bi.block.uid);
	}
	def recurseOnChildren(f: SsaBlockInfo -> void, block: SsaBlockInfo) {
		for (bi = block.dom_child; bi != null; bi = bi.dom_sibling) {
			f(bi);
		}
	}
	def findJoins(bi: SsaBlockInfo) -> List<SsaBlockInfo> {
		var list: List<SsaBlockInfo>;
		for (c = bi.dom_child; c != null; c = c.dom_sibling) {
			if (c.block.preds.length > 1) list = List.new(c, list);
		}
		return list;
	}
	def findLoopRemainder(bi: SsaBlockInfo) -> List<SsaBlockInfo> {
		var list: List<SsaBlockInfo>;
		for (c = bi.dom_child; c != null; c = c.dom_sibling) {
//			if (!bi.loop.contains(c)) list = List.new(c, list);
			if (c.dom_parent == null) list = List.new(c, list);
		}
		return list;
	}

	// Adjust the dominator tree so that loop bodies do not dominate
	// blocks that are not in the loop. Only loop headers may
	// immediately dominate blocks not in the loop (i.e. after an exit).
	def loopStack = Vector<SsaLoopInfo>.new();
	def loopRemainder = Vector<List<SsaBlockInfo>>.new();
	def hoistLoopRemaindersInDomTree(bi: SsaBlockInfo) {
		if (bi.loop != null) {  // encountered a new loop
			loopStack.add(bi.loop);
			loopRemainder.add(null);
		}
		var top = loopStack.length - 1;
		for (ci = bi.dom_child; ci != null; ci = ci.dom_sibling) {
			// Recurse on immediately dominated children.
			if (top < 0 || loopStack[top].contains(ci) || isEndBlock(ci)) {
				// If not in a loop, or the child is in the loop, or the block
				// is a trivial end block, simply recurse.
				hoistLoopRemaindersInDomTree(ci);
				continue;
			}
			// Find the outermost loop of which the child is not a member
			// and add this child to that loop's remainder.
			for (i = top; i >= 0; i--) {
				if (!loopStack[i].contains(ci)) {
					loopRemainder[i] = List.new(ci, loopRemainder[i]);
					break;
				}
			}
		}
		if (bi.loop != null) {
			// Pop a loop off the loop stack and process the loop remainder.
			loopStack.length--;
			var remainder = loopRemainder[--loopRemainder.length];
			// Hoist the remainder nodes to be children of the loop header.
			for (l = remainder; l != null; l = l.tail) {
				moveToDomList(bi, l.head);
			}
			// Loop remainder nodes may still dominate other nodes that are
			// in the loop remainder of outer loops.
			for (l = remainder; l != null; l = l.tail) {
				hoistLoopRemaindersInDomTree(l.head);
			}
		}
	}
	def moveToDomList(bi: SsaBlockInfo, ci: SsaBlockInfo) {
		Terminal.put2("move @%1 to loop remainder of @%2\n", ci.block.uid, bi.block.uid);
		var prev: SsaBlockInfo;
		for (pl = ci.dom_parent.dom_child; pl != null; (prev = pl, pl = pl.dom_sibling)) {
			if (ci == pl) {
				if (prev != null) prev.dom_sibling = ci.dom_sibling;
				else ci.dom_parent.dom_child = ci.dom_sibling;
				break;
			}
		}
		ci.dom_sibling = bi.dom_child;
		bi.dom_child = ci;
		ci.dom_parent = null;
	}
	def isEndBlock(bi: SsaBlockInfo) -> bool {
		return bi.block.succs().length == 0;
	}

	def print() {
		var buf = StringBuffer.new();
		var depth = 0;
		for (i < code.length) {
			for (i < depth) buf.sp().sp();
			match (code[i]) {
				Block(t, bi) => {
					buf.format1("block[@%1]: ", bi.block.uid); // TODO: type
					depth++;
				}
				Loop(bi) => {
					buf.format1("loop[head=@%1]: ", bi.block.uid); // TODO: type
					depth++;
				}
				Body(bi) => {
					buf.format1("instrs[@%1]", bi.block.uid);
				}
				If(t, join) => {
					var jid = if(join != null, join.block.uid, -1);
					buf.format1("if[join=@%1]: ", jid); // TODO: type
					depth++;
				}
				Else => {
					buf.length -= 2;  // TODO: ugly
					buf.puts("else");
				}
				End => {
					buf.length -= 2; // TODO: ugly
					buf.puts("end");
					depth--;
				}
				Br(bi, reldepth) => {
					buf.format2("br[target=@%1] depth-%2", bi.block.uid, reldepth);
				}
				BrIf(bi, reldepth) => {
					buf.format2("br_if[target=@%1] depth-%2", bi.block.uid, reldepth);
				}
				BrTable(min, reldepths) => {
					buf.format1("br_table[min=%1] ", min);
					for (i < reldepths.length) {
						if (i > 0) buf.putc(',');
						buf.putc('-');
						buf.puti(reldepths[i]);
					}
				}
			}
			Terminal.putbln(buf);
			buf.reset();
		}
	}

	// Simple optimizer removes redundant constructs.
	def optimize() {
		var i = 0;
		for (p < code.length) {
			var c = code[p];
			code[i++] = c;
			if (c == CfgInstr.End) i = optimizeEnd(i);
			else if (c == CfgInstr.Else) i = optimizeElse(i);
		}
		code.length = i;
	}
	def optimizeEnd(i: int) -> int {
		match (code[i - 2]) {
			If,			// if end => 
			Loop,			// loop end =>
			Block => return i - 2;	// block end =>
			Else => return optimizeEnd(removeSecondToLast(i));	// else end => end
			Br(bi, depth) => {
				if (redundantBranch(bi, depth)) return optimizeEnd(removeSecondToLast(i));
			}
			_ => ;
		}
		return i;
	}
	def optimizeElse(i: int) -> int {
		match (code[i - 2]) {
			If(t, join) => { // if else => block
				code[i - 2] = CfgInstr.Block(t, join);
				return i - 1;
			}
			Br(bi, depth) => {
				if (redundantBranch(bi, depth)) return optimizeElse(removeSecondToLast(i));
			}
			_ => ;
		}
		return i;
	}
	def redundantBranch(bi: SsaBlockInfo, depth: int) -> bool {
		return (depth == 0 && bi.loop == null);
	}
	def removeSecondToLast(i: int) -> int {
		code[i - 2] = code[i - 1];
		return i - 1;
	}
}
