// Copyright 2021 Ben L. Titzer. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

def I_ADDQ   = 0x02;
def I_ORQ    = 0x03;
def I_ADCQ   = 0x04;
def I_SBBQ   = 0x05;
def I_ANDQ   = 0x06;
def I_SUBQ   = 0x07;
def I_XORQ   = 0x08;
def I_CMPQ   = 0x09;
def I_JMP    = 0x0a;
def I_JC     = 0x0b;
def I_SETC   = 0x0c;
def I_CMOVC  = 0x0d;
def I_THROW  = 0x0e;
def I_THROWC = 0x0f;
def I_SWITCH = 0x10;
def I_MULQ   = 0x12;
def I_NEGQ   = 0x13;
def I_NOTQ   = 0x14;
def I_TESTQ  = 0x15;
def I_MOV    = 0x16;
def I_LEAQ   = 0x18;
def I_LD8    = 0x19;
def I_LDS8   = 0x1a;
def I_LDU8   = 0x1b;
def I_LD16   = 0x1c;
def I_LDS16  = 0x1d;
def I_LDU16  = 0x1e;
def I_LD32   = 0x1f;
def I_LD64   = 0x20;
def I_ST8    = 0x21;
def I_ST16   = 0x22;
def I_ST32   = 0x23;
def I_ST64   = 0x24;
def I_CMPXCHG8   = 0x25;
def I_CMPXCHG16  = 0x26;
def I_CMPXCHG32  = 0x27;
def I_CMPXCHG64  = 0x28;
def I_DIVQ   = 0x29;
def I_IDIVQ  = 0x2a;
def I_INCQ   = 0x2b;
def I_DECQ   = 0x2c;
def I_SHLQ   = 0x2d;
def I_SARQ   = 0x2e;
def I_SHRQ   = 0x2f;
def I_SEXT   = 0x30;
def I_CALL   = 0x31;
def I_CALLER_IP = 0x32;
def I_CALLER_SP = 0x33;
// Addressing modes:
// REG = register, OP = register/stack, IMM = immediate
// MRRSD = [reg + reg * scale + disp]
def AM_NONE	   = 0x00;
def AM_OP_REG	   = 0x01;
def AM_OP_IMM	   = 0x02;
def AM_REG_OP	   = 0x03;
def AM_ADDR_IMM  = 0x04;
def AM_ADDR_REG  = 0x05;
def AM_MRRSD_REG = 0x06;
def AM_MRRSD_IMM = 0x07;
def AM_REG_MRRSD = 0x08;
def AM_OP	   = 0x09;

def AM_SHIFT = u5.view(8);
def COND_SHIFT = u5.view(12);

def ABS_MARKER = 0x11223344;
def REL_MARKER = 0xAABBCCDD;

def MATCH_NEG = true;
def MATCH_OP_I = true;
def MATCH_ADDR_ADD = true;
def MATCH_ADDR_ADD_IMM = true;
def MATCH_ADDR_SCALE = true;
def MATCH_SCALE = true;

def Regs: X86_64RegSet;
def Conds: X86_64Conds;

// Generates X86-64 machine code from SSA.
class SsaX86_64Gen extends SsaMachGen {
	def asm: X86_64Assembler;
	def m = SsaInstrMatcher.new();

	new(context: SsaContext, mach: MachProgram, asm, w: MachDataWriter) super(context, mach, Regs.SET, w) {
		anyReg = Regs.GPR_CLASS;
	}

	def visitApply(block: SsaBlock, i: SsaApplyOp) {
		match (i.op.opcode) {
			IntAdd => emitSimpleBinop(I_ADDQ, i, m.intbinop(i));
			IntSub => {
				var yval = m.intbinop(i);
				if (MATCH_NEG && m.xconst && m.xint == 0) return emit1(I_NEGQ | (AM_OP << AM_SHIFT), ovwReg(i, m.y));
				emitSimpleBinop(I_SUBQ, i, yval);
			}
			IntMul => {
				// XXX: multiply by 1, 2, 3, 4, 5, 9, powers of 2
				var yval = m.intbinop(i);
				if (MATCH_OP_I && m.yconst) return emit2(I_MULQ | (AM_OP_IMM << AM_SHIFT), ovwReg(i, m.x), useInt(yval));
				return emit2(I_MULQ | (AM_REG_OP << AM_SHIFT), ovwReg(i, m.x), use(m.y));
			}
			IntDiv => {
				// TODO: signed / cdq
				var signed = V3.isSigned(i.op.typeArgs[0]);
				var d = dfnFixed(i, Regs.RAX);
				var x = kill(-1, Regs.RDX);
				var a = useFixed(i.input0(), Regs.RAX);
				var b = useConstant(context.graph.zeroConst(), Regs.RDX);
				var c = useFixed(i.input1(), Regs.NOT_RAX_RDX);
				// TODO: source position for DivideByZeroException
				return emitN(if(signed, I_IDIVQ, I_DIVQ));
			}
			IntMod => {
				// TODO: signed / cdq
				var signed = V3.isSigned(i.op.typeArgs[0]);
				var d = dfnFixed(i, Regs.RDX);
				var x = kill(-1, Regs.RAX);
				var a = useFixed(i.input0(), Regs.RAX);
				var b = useConstant(context.graph.zeroConst(), Regs.RDX);
				var c = useFixed(i.input1(), Regs.NOT_RAX_RDX);
				// TODO: source position for DivideByZeroException
				return emitN(if(signed, I_IDIVQ, I_DIVQ));
			}
			IntAnd => emitSimpleBinop(I_ANDQ, i, m.intbinop(i));
			IntOr => emitSimpleBinop(I_ORQ, i, m.intbinop(i));
			IntXor => emitSimpleBinop(I_XORQ, i, m.intbinop(i));
			IntShl => emitShift(block, i, I_SHLQ);
			IntSar => emitShift(block, i, I_SARQ);
			IntShr => emitShift(block, i, I_SHRQ);
			IntViewI => {
				var tt = IntType.!(i.op.typeArgs[1]);
				if (tt.width == 64) {
					// XXX: make sure nop int converts are removed by lowering
					emit2(I_MOV | (AM_REG_OP << AM_SHIFT), dfnReg(i), use(i.input0()));
				} else if (!tt.signed) {
					emit3(I_ANDQ, dfnReg(i), ovwReg(i, i.input0()), useImm(tt.max));
				} else {
					emit3(I_SEXT, dfnReg(i), ovwReg(i, i.input0()), useInt(tt.width));
				}
			}
			BoolEq,
			BoolNot,
			RefEq,
			IntEq,
			IntLt,
			IntLteq,
			PtrLt,
			PtrLteq => {
				var cmp = matchCmp(i, false);
				emitCmp(cmp);
				// TODO: zero-extend?
				emit1(ArchInstrs.FLAG_NO_GAP | I_SETC | encodeCond(cmp.cond), dfnFixed(i, Regs.GPR_CLASS));
			}
			ConditionalThrow(exception) => {
				var cmp = matchCmp(i.input0(), true);
				emitCmp(cmp);
				emit1(ArchInstrs.FLAG_NO_GAP | I_THROWC | encodeCond(cmp.cond), useExSource(exception, i.source));
			}
			PtrLoad => {
				var lt = i.op.typeArgs[1], size = mach.sizeOf(lt);
				var t = matchMrrsd(i.input0());
				if (size == 0) {
					useMrrsd(t);
					useInt(0);
					return emitN(I_TESTQ | AM_MRRSD_IMM << AM_SHIFT);
				}
				var opcode: int, signed = V3.isSigned(lt);
				// TODO: floating point loads
				match (size) {
					1 => opcode = if(signed, I_LDS8, I_LDU8);
					2 => opcode = if(signed, I_LDS16, I_LDU16);
					4 => opcode = I_LD32;
					8 => opcode = I_LD64;
					_ => context.fail("invalid size for load");
				}
				dfnReg(i);
				useMrrsd(t);
				// TODO: source position for NullCheckException
				return emitN(opcode | (AM_REG_MRRSD << AM_SHIFT));
			}
			PtrStore => {
				var lt = i.op.typeArgs[0], size = mach.sizeOf(lt);
				var t = matchMrrsd(i.input0());
				if (size == 0) {
					useMrrsd(t);
					useInt(0);
					return emitN(I_TESTQ | AM_MRRSD_IMM << AM_SHIFT);
				}
				var opcode: int;
				useMrrsd(t);
				useReg(i.input1()); // TODO: floating point stores
				match (size) {
					1 => opcode = I_ST8;
					2 => opcode = I_ST16;
					4 => opcode = I_ST32;
					8 => opcode = I_ST64;
					_ => context.fail("invalid size for store");
				}
				// TODO: source position for NullCheckException
				return emitN(opcode | (AM_MRRSD_REG << AM_SHIFT));
			}
			PtrCmpSwp => {
				var lt = i.op.typeArgs[0], size = mach.sizeOf(lt);
				var t = matchMrrsd(i.input0());
				var opcode: int;
				useMrrsd(t);
				var expect = useFixed(i.input1(), Regs.RAX);
				useFixed(i.input1(), Regs.NOT_RAX);
				match (size) {
					1 => opcode = I_CMPXCHG8;
					2 => opcode = I_CMPXCHG16;
					4 => opcode = I_CMPXCHG32;
					8 => opcode = I_CMPXCHG64;
					_ => context.fail("invalid size for cmpswp");
				}
				// TODO: source position for NullCheckException
				emitN(opcode | (AM_MRRSD_REG << AM_SHIFT)); // TODO: addressing mode is wrong
				emit1(ArchInstrs.FLAG_NO_GAP | I_SETC | encodeCond(X86_64Conds.Z), dfnReg(i));
			}
			PtrAdd => {
				// XXX: use binop matching for PtrAdd
				emit3(I_ADDQ, dfnReg(i), ovwReg(i, i.input0()), use(i.input1()));
			}
			PtrSub => {
				// XXX: use binop matching for PtrAdd
				emit3(I_SUBQ, dfnReg(i), ovwReg(i, i.input0()), use(i.input1()));
			}
			Alloc => ;	// TODO
			CallAddress(funcRep) => visitCall(block, i, funcRep);
			CallerIp => {
				emit1(I_CALLER_IP, dfnReg(i));
			}
			CallerSp => {
				emit1(I_CALLER_SP, dfnReg(i));
			}
			CallKernel => ; // TODO
			_ => return context.fail("unexpected opcode");
		}
	}
	def visitCall(block: SsaBlock, call: SsaApplyOp, funcRep: Mach_FuncRep) {
		var func = call.input0(), mi: MachInstr;
		var conv = frame.allocCallerSpace(X86_64VirgilCallConv.getForFunc(funcRep));

		// define the return value(s) of the call
		var rv = getProjections(call);
		for (i < rv.length) {
			dfnFixed(rv[i], conv.calleeRet(i));
		}
		// TODO: var lp = if(rtgc != null, livePoint());
		kill(newLivepoint(), Regs.ALL);	// XXX: manually split liveness across call?
		var skip = 0;
		if (SsaConst.?(func)) {
			var target = Address<IrMethod>.!(SsaConst.!(func).val);
			useImm(target);
			if (V3.isComponent(target.val.receiver)) skip = 1;
		} else {
			useReg(func);
		}

		// use the arguments to the call
		var inputs = call.inputs;
		for (i = 1 + skip; i < inputs.length; i++) {  // input[0] == func
			useFixed(inputs[i].dest, conv.calleeParam(i - 1));
		}
		emitN(I_CALL);
	}
	def emitShift(block: SsaBlock, i: SsaApplyOp, opcode: int) {
		var yval = m.intbinop(i);
		if (MATCH_OP_I && m.yconst) return emit2(opcode, ovwReg(i, m.x), useInt(yval));
		return emit2(opcode, ovwReg(i, m.x), useFixed(m.y, Regs.RCX));
	}
	def useMrrsd(x: SsaInstr, y: SsaInstr, scale: byte, disp: Val) {
		if (x == null) useInt(0); // no base register, will ignore
		else useReg(x);
		useReg(y);
		useInt(scale);
		useImm(disp);
	}
	def matchMrrsd(i: SsaInstr) -> (SsaInstr, SsaInstr, byte, Val) {
		var t = matchAddImm(i), disp = t.1;
		i = t.0;
		var xadd: SsaApplyOp;
		if (MATCH_ADDR_ADD && (xadd = cover(Opcode.PtrAdd.tag, i)) != null) {
			var x = xadd.input0(), y = xadd.input1();
			var ys = matchScale(y);
			if (ys.1 != 1) return (x, ys.0, ys.1, disp);
			var xs = matchScale(x);
			if (xs.1 != 1) return (y, xs.0, xs.1, disp);
			return (x, y, 1, disp);
		}
		var is = matchScale(i);
		return (null, is.0, is.1, disp);
	}
	def matchScale(i: SsaInstr) -> (SsaInstr, byte) {
		if (!MATCH_SCALE || !SsaApplyOp.?(i)) return (i, 1);
		var apply = SsaApplyOp.!(i);
		if (Opcode.IntMul.?(apply.op.opcode)) {
			var yval = m.intbinop(apply);
			if (!m.yconst) return (apply, 1);
			if (yval == 1) return (m.x, 1);
			if (yval == 2) return (m.x, 2);
			if (yval == 4) return (m.x, 4);
			if (yval == 8) return (m.x, 8);
		} else if (Opcode.IntShl.?(apply.op.opcode)) {
			var yval = m.intbinop(apply);
			if (!m.yconst) return (apply, 1);
			if (yval == 0) return (m.x, 1);
			if (yval == 1) return (m.x, 2);
			if (yval == 2) return (m.x, 4);
			if (yval == 3) return (m.x, 8);
		}
		return (apply, 1);
	}
	def emitSimpleBinop(opcode: int, i: SsaApplyOp, yval: int) {
		// XXX: select better left operand using liveness
		// XXX: cover loads with mrrsd operand
		if (MATCH_OP_I && m.yconst) return emit2(opcode, ovwReg(i, m.x), useInt(yval));
		return emit2(opcode, ovwReg(i, m.x), use(m.y));
	}
	def visitThrow(block: SsaBlock, i: SsaThrow) {
		emit1(I_THROW, useExSource(i.exception, i.source));
	}
	def visitIf(block: SsaBlock, i: SsaIf) {
		var key = i.input0(), cmp = matchCmp(key, true), succ = i.block().succ;
		var s0 = succ(0).dest, s1 = succ(1).dest, target: SsaBlock, jmp: SsaBlock;
		if (blocks.isImmediatelyAfter(context.block, s1)) { // fall through to s1
			target = s0;
		} else if (blocks.isImmediatelyAfter(context.block, s0)) {  // fall through to s0
			cmp = cmp.negate();
			target = s1;
		} else {  // cannot fall through
			target = s0;
			jmp = s1;
		}
		emitCmp(cmp);
		emit1(ArchInstrs.FLAG_NO_GAP | I_JC | encodeCond(cmp.cond), useLabel(target));
		if (jmp != null) emit1(ArchInstrs.FLAG_NO_GAP | I_JMP, useLabel(jmp));
	}
	def visitSwitch(block: SsaBlock, i: SsaSwitch) {
		use(i.input0());
		useImm(Int.box(i.minValue));
		useScratch();
		for (s in block.succs()) useLabel(s.dest);
		emitN(I_SWITCH);
	}
	def visitGoto(block: SsaBlock, i: SsaGoto) {
		var target = i.target();
		if (!blocks.isImmediatelyAfter(context.block, target)) {
			emit1(I_JMP, useLabel(target));  // jump to block if not successor
		}
	}

	def emitCmp(cmp: X86_64CmpMatch) {
		if (cmp.y == null) {
			emit2(I_CMPQ, use(cmp.x), useImm(cmp.val));
		} else {
			emit2(I_CMPQ, useReg(cmp.x), use(cmp.y));
		}
	}

	def assemble(opcode: int, a: Array<Operand>) {
		var start = asm.pos(), addr: Addr;
		var code = opcode & 0xff, mode = ((opcode >> AM_SHIFT) & 0xF);
		match (mode) {
			AM_NONE => {
				assemble_none(code, a);
			}
			AM_OP => {
				assemble_r(code, toRm(a[0]));
			}
			AM_OP_REG => {
				assemble_r_r(code, toRm(a[0]), toReg(a[1]));
			}
			AM_OP_IMM => {
				assemble_r_i(code, toRm(a[0]), toImm(a[1]));
			}
			AM_REG_OP => {
				assemble_r_r(code, toReg(a[0]), toRm(a[1]));
			}
			AM_MRRSD_REG => {
				var t = toMrrsd(a, 0);
				addr = t.1;
				assemble_m_r(code, t.0, toReg(a[4]));
			}
			AM_MRRSD_IMM => {
				var t = toMrrsd(a, 0);
				addr = t.1;
				assemble_m_i(code, t.0, toImm(a[3]));
			}
			AM_REG_MRRSD => {
				var t = toMrrsd(a, 1);
				addr = t.1;
				assemble_r_m(code, toReg(a[0]), t.0);
			}
			_ => return context.fail1("unknown addressing mode %d", mode);
		}
//TODO		if (addr != null) asm.recordPatch(asm.findAbsConst(start), addr);
	}
	def assemble_r(code: int, a: X86_64Gpr) {
		match (code) {
			I_NEGQ => asm.negq_r(a);
			I_NOTQ => asm.notq_r(a);
			I_MULQ => asm.imulq_r(a);
			I_DIVQ => asm.divq_r(a);
			I_IDIVQ => asm.idivq_r(a);
			I_INCQ => asm.incq_r(a);
			I_DECQ => asm.decq_r(a);
			I_SHLQ => asm.shlq_r_cl(a);
			I_SARQ => asm.sarq_r_cl(a);
			I_SHRQ => asm.shrq_r_cl(a);
		}
	}
	def assemble_r_r(code: int, a: X86_64Gpr, b: X86_64Gpr) {
		match (code) {
			I_ADDQ => asm.addq_r_r(a, b);
			I_ORQ => asm.orq_r_r(a, b);
			I_ADCQ => asm.adcq_r_r(a, b);
			I_SBBQ => asm.sbbq_r_r(a, b);
			I_ANDQ => asm.andq_r_r(a, b);
			I_SUBQ => asm.subq_r_r(a, b);
			I_XORQ => asm.xorq_r_r(a, b);
			I_CMPQ => asm.cmpq_r_r(a, b);
			I_MULQ => asm.imulq_r_r(a, b);
			I_MOV => asm.movd_r_r(a, b);
			I_LD8 => asm.movb_r_r(a, b);
			I_LDS8 => asm.movbsx_r_r(a, b);
			I_LDU8 => asm.movbzx_r_r(a, b);
			I_LDS16 => asm.movwsx_r_r(a, b);
			I_LDU16 => asm.movwzx_r_r(a, b);
			I_LD32 => asm.movd_r_r(a, b);
			I_LD64 => asm.movq_r_r(a, b);
			_ => return context.fail1("invalid opcode %d", code);
		}
	}
	def assemble_m_r(code: int, a: X86_64Addr, b: X86_64Gpr) {
		match (code) {
			I_ADDQ => asm.addq_m_r(a, b);
			I_ORQ =>  asm.orq_m_r(a, b);
			I_ADCQ => asm.adcq_m_r(a, b);
			I_SBBQ => asm.sbbq_m_r(a, b);
			I_ANDQ => asm.andq_m_r(a, b);
			I_SUBQ => asm.subq_m_r(a, b);
			I_XORQ => asm.xorq_m_r(a, b);
			I_CMPQ => asm.cmpq_m_r(a, b);
			I_TESTQ => asm.testq_m_r(a, b);
			I_ST8 => asm.movb_m_r(a, b);
			I_ST16 => asm.movw_m_r(a, b);
			I_ST32 => asm.movd_m_r(a, b);
			I_ST64 => asm.movq_m_r(a, b);
			I_CMPXCHG8 => asm.cmpxchgb_m_r(a, b);
			I_CMPXCHG16 => asm.cmpxchgw_m_r(a, b);
			I_CMPXCHG32 => asm.cmpxchgd_m_r(a, b);
			I_CMPXCHG64 => asm.cmpxchgq_m_r(a, b);
			_ => return context.fail1("invalid opcode %d", code);
		}
	}
	def assemble_r_m(code: int, a: X86_64Gpr, b: X86_64Addr) {
		match (code) {
			I_ADDQ => asm.addq_r_m(a, b);
			I_ORQ =>  asm.orq_r_m(a, b);
			I_ADCQ => asm.adcq_r_m(a, b);
			I_SBBQ => asm.sbbq_r_m(a, b);
			I_ANDQ => asm.andq_r_m(a, b);
			I_SUBQ => asm.subq_r_m(a, b);
			I_XORQ => asm.xorq_r_m(a, b);
			I_CMPQ => asm.cmpq_r_m(a, b);
//TODO			I_TEST => asm.testq_r_m(a, b);
			I_ST8 => asm.movb_r_m(a, b);
			I_ST16 => asm.movw_r_m(a, b);
			I_ST32 => asm.movd_r_m(a, b);
//TODO			I_CMPXCHG8 => asm.cmpxchgb_r_m(a, b);
//TODO			I_CMPXCHG16 => asm.cmpxchgw_r_m(a, b);
//TODO			I_CMPXCHG32 => asm.cmpxchgd_r_m(a, b);
			_ => return context.fail1("invalid opcode %d", code);
		}
	}
	def assemble_m_i(code: int, a: X86_64Addr, val: Val) {
		var b: int = Int.unbox(val); // TODO
		match (code) {
			I_ADDQ => asm.addq_m_i(a, b);
			I_ORQ =>  asm.orq_m_i(a, b);
			I_ADCQ => asm.adcq_m_i(a, b);
			I_SBBQ => asm.sbbq_m_i(a, b);
			I_ANDQ => asm.andq_m_i(a, b);
			I_SUBQ => asm.subq_m_i(a, b);
			I_XORQ => asm.xorq_m_i(a, b);
			I_CMPQ => asm.cmpq_m_i(a, b);
			I_TESTQ => asm.testq_m_i(a, b);
			I_ST8 => asm.movb_m_i(a, b);
			I_ST16 => asm.movw_m_i(a, b);
			I_ST32 => asm.movd_m_i(a, b);
//TODO			I_CMPXCHG8 => asm.cmpxchgb_m_i(a, b);
//TODO			I_CMPXCHG16 => asm.cmpxchgw_m_i(a, b);
//TODO			I_CMPXCHG32 => asm.cmpxchgd_m_i(a, b);
			_ => return context.fail1("invalid opcode %d", code);
		}
	}
	def assemble_r_i(code: int, a: X86_64Gpr, val: Val) {
		var b = if(Addr.?(val), ABS_MARKER, Int.unbox(val));
		match (code) {
			I_ADDQ => asm.addq_r_i(a, b);
			I_ORQ =>  asm.orq_r_i(a, b);
			I_ADCQ => asm.adcq_r_i(a, b);
			I_SBBQ => asm.sbbq_r_i(a, b);
			I_ANDQ => asm.andq_r_i(a, b);
			I_SUBQ => asm.subq_r_i(a, b);
			I_XORQ => asm.xorq_r_i(a, b);
			I_CMPQ => asm.cmpq_r_i(a, b);
			I_TESTQ => asm.testq_r_i(a, b);
			I_SHLQ => asm.shlq_r_i(a, u6.view(b));
			I_SARQ => asm.sarq_r_i(a, u6.view(b));
			I_SHRQ => asm.shrq_r_i(a, u6.view(b));
			_ => return context.fail1("invalid opcode %d", code);
		}
		if (Addr.?(val)) {
//TODO			asm.recordPatch(asm.pos() - 4, Addr.!(val));  // XXX: manual patch record
		}
	}
	def assemble_none(code: int, a: Array<Operand>) {
		match (code) {
			I_JMP => {
				var label = toLabel(a[0]);
				if (label.pos >= 0) asm.j(Conds.ALWAYS, label.pos - asm.pos());
				else asm.j(Conds.ALWAYS, REL_MARKER);
				recordRelLabel(asm.pos() - 4, label);
			}
			I_JC => {
				var label = toLabel(a[0]), cond = decodeCond(code);
				if (label.pos >= 0) asm.j(cond, label.pos - asm.pos());
				else asm.j(cond, REL_MARKER);
				recordRelLabel(asm.pos() - 4, label);
			}
			I_SETC => {
				var reg = toReg(a[0]), cond = decodeCond(code);
				asm.set_r(cond, reg);
				asm.movbzx_r_r(reg, reg); // XXX: remove zero extend for setc?
			}
			I_CMOVC => {
				var reg = toReg(a[0]), cond = decodeCond(code), rm = toRm(a[1]);
				asm.cmov_r(cond, reg, rm);
			}
			I_THROW => {
				var exSource = toExSource(a[0]);
//TODO				asm.jmpx_addr(Conds.ALWAYS, mach.runtime.getExceptionDest(asm.codeOffset(), exSource.0, exSource.1));
			}
			I_THROWC => {
				var exSource = toExSource(a[0]), cond = decodeCond(code);
//TODO				asm.jmpx_addr(cond, mach.runtime.getExceptionDest(asm.codeOffset(), exSource.0, exSource.1));
			}
			I_NEGQ => {
				asm.negq_r(toReg(a[0]));
			}
			ArchInstrs.ARCH_BLOCK => {
//TODO				asm.bind(toLabel(a[0]));
			}
			ArchInstrs.ARCH_ENTRY => {
				var adjust = frameAdjust();
				if (adjust > 0) asm.subq_r_i(X86_64Regs.RSP, adjust); // allocate frame
			}
			ArchInstrs.ARCH_RET => {
				var adjust = frameAdjust();
				if (adjust > 0) asm.addq_r_i(X86_64Regs.RSP, adjust); // deallocate frame
				asm.ret();
			}
			I_SWITCH => {
				var size = a.length - 4;
				var key = toRm(a[0]), minValue = Int.unbox(toImm(a[1])), scratchReg = toReg(a[1]);
				asm.movq_r_r(scratchReg, key);
				if (minValue != 0) asm.subq_r_i(scratchReg, minValue);
				asm.cmpq_r_i(scratchReg, size - 1);
				asm.j(X86_64Conds.A, REL_MARKER);
				recordRelLabel(asm.pos() - 4, toLabel(a[a.length - 1]));
				// load from the jump table to follow
				var start = asm.pos();
				asm.movd_r_m(scratchReg, X86_64Addr.new(null, scratchReg, 8, X86Addrs.ABS_CONST));
				var jtaddrpos: int; //TODO = asm.findAbsConst(start);
				asm.ijmp_r(scratchReg);
				// align and emit the jump table
				w.align(4);
				var jumpTableAddr = w.posAddr();
				w.at(jtaddrpos).put_b32(jumpTableAddr);
				w.atEnd();
				// emit jump table
				for (i < size) {
					recordAbsLabel(asm.pos(), toLabel(a[i]));
					w.zeroN(4);
				}
			}
			I_SEXT => {
				var reg = toReg(a[0]), width = toInt(a[1]);
				asm.shlq_r_i(reg, u6.view(64 - width));
				asm.sarq_r_i(reg, u6.view(64 - width));
			}
			I_CALL => {
				var target = a[0];
				if (Operand.Immediate.?(target)) {
//TODO					asm.call_addr(Addr.!(Operand.Immediate.!(target).val));
				} else {
					asm.icall_r(toReg(target));
				}
				// TODO: record source, record GC map
			}
			I_CALLER_IP => {
				asm.movd_r_m(toReg(a[0]), X86_64Regs.RSP.plus(frameAdjust()));
			}
			I_CALLER_SP => {
				asm.leaq(toReg(a[0]), X86_64Regs.RSP.plus(frameAdjust()));
			}
			_ => return context.fail1("unexpected X86 opcode %d", code);
		}
	}
	def toMrrsd(a: Array<Operand>, start: int) -> (X86_64Addr, Addr) {
		// TODO: first operand to MRRSD
		var r = toReg(a[start + 1]), scale = byte.view(toInt(a[start + 2]));
		var val = toImm(a[start + 3]);
		if (Addr.?(val)) return (X86_64Addr.new(null, r, scale, ABS_MARKER), Addr.!(val));
		else return (X86_64Addr.new(null, r, scale, Int.unbox(val)), null);
	}

	def matchCmp(i: SsaInstr, inblock: bool) -> X86_64CmpMatch {
		if ((inblock && !inSameBlock(i)) || !SsaApplyOp.?(i)) return X86_64CmpMatch.new(Conds.NZ, i, null, null);
		match (SsaApplyOp.!(i).op.opcode) {
			BoolEq,
			IntEq,
			RefEq =>		return newCmp(i, Conds.Z);
			IntLt =>		return newCmp(i, signedCmp(i, Conds.L, Conds.C));
			IntLteq =>		return newCmp(i, signedCmp(i, Conds.LE, Conds.NA));
			PtrLt =>		return newCmp(i, Conds.C);
			PtrLteq =>		return newCmp(i, Conds.NA);
			BoolNot => {
				var cmp = matchCmp(i.input0(), inblock);
				return X86_64CmpMatch.new(cmp.cond.negate, cmp.x, cmp.y, cmp.val);
			}
			_ => ;
		}
		return X86_64CmpMatch.new(Conds.NZ, i, null, null);
	}
	def signedCmp(i: SsaInstr, signed: X86_64Cond, unsigned: X86_64Cond) -> X86_64Cond {
		return if(V3.isSigned(SsaApplyOp.!(i).op.sig.paramTypes[0]), signed, unsigned);
	}
	def newCmp(i: SsaInstr, cond: X86_64Cond) -> X86_64CmpMatch {
		var x = i.input0(), y = i.input1();
		if (SsaConst.?(y)) return X86_64CmpMatch.new(cond, x, null, SsaConst.!(y).val);
		if (SsaConst.?(x) && cond.commute != null) return X86_64CmpMatch.new(cond.commute, y, null, SsaConst.!(x).val);
		return X86_64CmpMatch.new(cond, x, y, null);
	}

	def frameAdjust() -> int {
		// assumes return address already pushed
		return frame.size() - mach.code.addressSize;
	}
	def toReg(o: Operand) -> X86_64Gpr {
		match (o) {
			Overwrite(i, dst, src, assignment) => return loc_r(assignment);
			Def(i, vreg, assignment) => return loc_r(assignment);
			Use(i, vreg, assignment) => return loc_r(assignment);
			_ => return V3.fail("expected register");
		}
	}
	def toRm(o: Operand) -> X86_64Gpr { // XXX: allow spilled arguments too
		match (o) {
			Overwrite(i, dst, src, assignment) => return loc_rm(assignment);
			Def(i, vreg, assignment) => return loc_rm(assignment);
			Use(i, vreg, assignment) => return loc_rm(assignment);
			_ => return V3.fail("expected register");
		}
	}

	def encodeCond(cond: X86_64Cond) -> int {
		return cond.index << COND_SHIFT;
	}
	def decodeCond(opcode: int) -> X86_64Cond {
		return Conds.all[(opcode >> COND_SHIFT) & 0xF];
	}

	def recordAbsLabel(pos: int, label: Label) {} // TODO
	def recordRelLabel(pos: int, label: Label) {} // TODO
	def loc_r(loc: int) -> X86_64Gpr;
	def loc_rm(loc: int) -> X86_64Gpr; // TODO: allow spilled arguments
	def getOutput() -> ArchInstrBuffer {
		if (out != null) return out;
		return out = X86InstrBuffer.new(this, context.prog, regSet);
	}
}
class X86InstrBuffer extends ArchInstrBuffer {
	def x86codegen: SsaX86_64Gen;
	new(x86codegen, prog: Program, regSet: MachRegSet) super(x86codegen, prog, regSet) { }
	def putArchInstr(indent: int, i: ArchInstr) -> int {
		var opcode = int.view(i.opcode()), a = i.operands;
		var name: string, cond: X86_64Cond;
		match (opcode & 0xFF) {
			I_SWITCH => name = "switch";
			I_ADDQ => name = "addq";
			I_ORQ =>  name = "orq";
			I_ADCQ => name = "adcq";
			I_SBBQ => name = "sbbq";
			I_ANDQ => name = "andq";
			I_SUBQ => name = "subq";
			I_CMPQ => name = "cmpq";
			I_MULQ => name = "imulq";
			I_DIVQ => name = "divq";
			I_IDIVQ => name = "idivq";
			I_NEGQ => name = "negq";
			I_NOTQ => name = "notq";
			I_LEAQ => name = "leaq";
			I_TESTQ => name = "testq";
			I_LD8 => name = "movb";
			I_LDS8 => name = "movbsx";
			I_LDU8 => name = "movbzx";
			I_LD16 => name = "movw";
			I_LDS16 => name = "movwsx";
			I_LDU16 => name = "movwzx";
			I_LD32 => name = "movd";
			I_LD64 => name = "movq";
			I_ST8 => name = "movb";
			I_ST16 => name = "movw";
			I_ST32 => name = "movd";
			I_ST64 => name = "movq";
			I_CMPXCHG8 => name = "cmpxchgb";
			I_CMPXCHG16 => name = "cmpxchgw";
			I_CMPXCHG32 => name = "cmpxchgd";
			I_CMPXCHG64 => name = "cmpxchgq";
			I_INCQ => name = "incq";
			I_DECQ => name = "decq";
			I_SHLQ => name = "shlq";
			I_SARQ => name = "sarq";
			I_SHRQ => name = "shrq";
			I_SEXT => name = "sext";
			I_CALL => name = "call";
			I_CALLER_IP => name = "caller_ip";
			I_CALLER_SP => name = "caller_sp";
			I_JMP => name = "j";
			I_SETC => {
				name = "set";
				cond = x86codegen.decodeCond(opcode);
			}
			I_CMOVC => {
				name = "cmov";
				cond = x86codegen.decodeCond(opcode);
			}
			I_JC => {
				name = "j";
				cond = x86codegen.decodeCond(opcode);
			}
			ArchInstrs.ARCH_RET => {
				putIndent(indent);
				puts(name);
				sp();
				if (codegen.frame.frameSize < 0) puts("?");
				else putd(x86codegen.frameAdjust());
				sp();
				putOperands(a);
				return indent;
			}
			I_THROW => {
				name = "j";
			}
			I_THROWC => {
				name = "j";
				cond = x86codegen.decodeCond(opcode);
			}
			_ => {
				return putSimpleInstr(indent, i);
			}
		}
		match ((opcode >> AM_SHIFT & 0xF)) {
			AM_MRRSD_REG,
			AM_MRRSD_IMM => {
				putIndent(indent);
				puts(name);
				if (cond != null) puts(cond.name);
				sp();
				var offset = renderMrrsd(a, 0);
				csp();
				putOperand(a[offset]);
			}
			AM_REG_MRRSD => {
				putIndent(indent);
				puts(name);
				if (cond != null) puts(cond.name);
				sp();
				putOperand(a[0]);
				csp();
				var offset = renderMrrsd(a, 1);
			}
			_ => {
				putIndent(indent);
				puts(name);
				if (cond != null) puts(cond.name);
				sp();
				putOperands(a);
			}
		}


		return indent;
	}
	def renderMrrsd(a: Array<Operand>, start: int) -> int {
		var x = a[start], y = a[start + 1], scale = codegen.toInt(a[start + 2]), disp = codegen.toImm(a[start + 3]);
		putc('[');
		if (!Operand.Immediate.?(x)) {
			putOperand(x);
			puts(" + ");
		}
		putOperand(y);
		if (scale > 1) {
			puts(" * ");
			putd(scale);
		}
		if (disp != null) {
			puts(" + ");
			V3.renderResult(disp, null, this);
		}
		putc(']');
		return 3;
	}
}
// Pattern match of a comparison between two vars or a var and a constant
class X86_64CmpMatch {
	def cond: X86_64Cond;
	def x: SsaInstr;
	def y: SsaInstr;
	def val: Val;
	new(cond, x, y, val) { }
	def negate() -> X86_64CmpMatch { return X86_64CmpMatch.new(cond.negate, x, y, val); }
}
